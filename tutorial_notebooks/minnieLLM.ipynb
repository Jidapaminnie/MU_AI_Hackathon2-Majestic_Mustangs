{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.legacy import (\n",
    "    KeywordTableIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    download_loader,\n",
    "    load_index_from_storage,\n",
    "    VectorStoreIndex)\n",
    "\n",
    "from llama_index.legacy.llms.vertex import Vertex\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from llama_index.legacy.llms.langchain import LangChainLLM\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from llama_index.legacy.embeddings import LangchainEmbedding\n",
    "from llama_index.legacy import Document\n",
    "from llama_index.legacy.node_parser import SimpleNodeParser, HierarchicalNodeParser\n",
    "\n",
    "\n",
    "\n",
    "from llama_index.legacy.vector_stores.chroma import ChromaVectorStore\n",
    "import chromadb\n",
    "\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "from llama_index.legacy import set_global_service_context\n",
    "from google.cloud import aiplatform\n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports from og llama index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.legacy import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.legacy.embeddings import LangchainEmbedding\n",
    "from llama_index.legacy.text_splitter import TokenTextSplitter\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from llama_index.legacy.llms.vertex import Vertex\n",
    "from llama_index.legacy.node_parser import SimpleNodeParser, HierarchicalNodeParser\n",
    "from llama_index.legacy import (\n",
    "    KeywordTableIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    ServiceContext,\n",
    "    StorageContext,\n",
    "    download_loader,\n",
    "    load_index_from_storage,\n",
    "    VectorStoreIndex)\n",
    "from llama_index.legacy.retrievers import VectorIndexRetriever\n",
    "from llama_index.legacy.prompts import (\n",
    "    ChatMessage,\n",
    "    ChatPromptTemplate,\n",
    "    MessageRole,\n",
    "    PromptTemplate,\n",
    ")\n",
    "\n",
    "from llama_index.legacy.postprocessor import NERPIINodePostprocessor, SentenceEmbeddingOptimizer\n",
    "from llama_index.legacy import ServiceContext\n",
    "from llama_index.legacy.schema import QueryBundle\n",
    "from llama_index.legacy.schema import NodeWithScore, TextNode\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "from llama_index.legacy import set_global_service_context\n",
    "import re\n",
    "import uuid\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import csv\n",
    "from typing import List, Tuple, Dict\n",
    "import time\n",
    "\n",
    "from llama_index.legacy.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.legacy import StorageContext\n",
    "from llama_index.legacy.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from IPython.display import Markdown, display\n",
    "import chromadb\n",
    "from llama_index.core import Settings\n",
    "\n",
    "from llama_index.legacy.llms.langchain import LangChainLLM\n",
    "from langchain.chat_models import ChatVertexAI\n",
    "from llama_index.legacy import Response\n",
    "from llama_index.legacy.response_synthesizers import Refine\n",
    "from llama_index.legacy.evaluation import SemanticSimilarityEvaluator\n",
    "from llama_index.legacy.evaluation import RelevancyEvaluator\n",
    "from llama_index.legacy.embeddings import SimilarityMode\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# additional\n",
    "from llama_index.legacy.postprocessor import LongContextReorder\n",
    "from llama_index.legacy.retrievers import AutoMergingRetriever\n",
    "from llama_index.legacy.query_engine import TransformQueryEngine\n",
    "from llama_index.legacy.query_engine import RetrieverQueryEngine\n",
    "from llama_index.legacy.indices.query.query_transform.base import (\n",
    "    HyDEQueryTransform,StepDecomposeQueryTransform\n",
    ")\n",
    "from llama_index.legacy.node_parser import get_leaf_nodes\n",
    "\n",
    "# llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "# callback_manager = CallbackManager([llama_debug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Aekky\\anaconda3\\envs\\llama_env\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.vertexai.ChatVertexAI` was deprecated in langchain-community 0.0.12 and will be removed in 0.2.0. An updated version of the class exists in the langchain-google-vertexai package and should be used instead. To use it run `pip install -U langchain-google-vertexai` and import as `from langchain_google_vertexai import ChatVertexAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file(\"credentials\\\\vertex-test-417403-ce72ad032af7.json\")\n",
    "vertex_ai = Vertex(model=\"text-bison\", project=credentials.project_id, location= \"asia-southeast1\", credentials=credentials, temperature=0.2)\n",
    "chat_vertex_ai = ChatVertexAI(model_name=\"chat-bison-32k\", project=credentials.project_id, location= \"asia-southeast1\", credentials=credentials, temperature=0.2, max_output_tokens= 8192) # max for bison 32k                                 \n",
    "embed_model = LangchainEmbedding(VertexAIEmbeddings(model_name='textembedding-gecko-multilingual@latest'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ServiceContext(llm_predictor=LLMPredictor(system_prompt=None, query_wrapper_prompt=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>), prompt_helper=PromptHelper(context_window=3900, num_output=256, chunk_overlap_ratio=0.1, chunk_size_limit=None, separator=' '), embed_model=LangchainEmbedding(model_name='textembedding-gecko-multilingual@latest', embed_batch_size=10, callback_manager=<llama_index.legacy.callbacks.base.CallbackManager object at 0x0000022808433F90>), transformations=[SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.legacy.callbacks.base.CallbackManager object at 0x0000022808433F90>, id_func=<function default_id_func at 0x00000228784DD300>, chunk_size=1024, chunk_overlap=20, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?')], llama_logger=<llama_index.legacy.logger.base.LlamaLogger object at 0x00000228544F4A50>, callback_manager=<llama_index.legacy.callbacks.base.CallbackManager object at 0x0000022808433F90>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_context = ServiceContext.from_defaults(llm=vertex_ai, embed_model=embed_model, chunk_size=1024, chunk_overlap=20)\n",
    "set_global_service_context(service_context)\n",
    "# need to set global service context becuase if not index = VectorStoreIndex.from_vector_store(vector_store, embed_model=Settings.embed_model) will produce an error\n",
    "# it will say that it requires OPENAI key etc\n",
    "service_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"baby_0_3.json\"\n",
    "with open(json_file, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "    \n",
    "# print(\"the number of documents: \" , len(json_data))\n",
    "# for i in json_data:\n",
    "#     print(i) # str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to create documents from a list of strings: \n",
    "https://docs.llamaindex.ai/en/stable/module_guides/loading/documents_and_nodes/usage_documents.html#defining-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [Document(text=t) for t in json_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create local ChromaDB Vectore Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create index and persist to Chroma vector store\n",
    "\n",
    "# db = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "# chroma_collection = db.get_or_create_collection(\"chroma_db\")\n",
    "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# index = VectorStoreIndex.from_documents(\n",
    "#     documents = docs, storage_context=storage_context, embed_model=embed_model\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index from persisted vector store\n",
    "\n",
    "db = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"chroma_db\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical Node Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = HierarchicalNodeParser.from_defaults(\n",
    "    chunk_sizes=[1024, 512, 256]\n",
    ")\n",
    "nodes = node_parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_nodes = get_leaf_nodes(nodes)\n",
    "nodes_by_id = {node.node_id: node for node in nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_merging_context = ServiceContext.from_defaults(\n",
    "    llm=LangChainLLM(ChatVertexAI(model_name=\"chat-bison@002\",\n",
    "                                         temperature=0.2,\n",
    "                                         max_output_tokens=256)\n",
    "                                         ),\n",
    "    embed_model= LangchainEmbedding(VertexAIEmbeddings(model_name='textembedding-gecko-multilingual@latest')),\n",
    "    node_parser=node_parser,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults()\n",
    "storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "automerging_index = VectorStoreIndex(\n",
    "    leaf_nodes, storage_context=storage_context, service_context=auto_merging_context\n",
    ")\n",
    "\n",
    "automerging_index.storage_context.persist(persist_dir=\"./merging_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "automerging_retriever = automerging_index.as_retriever(\n",
    "    similarity_top_k=10\n",
    ")\n",
    "\n",
    "retriever = AutoMergingRetriever(\n",
    "    automerging_retriever, \n",
    "    automerging_index.storage_context, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorder = LongContextReorder()\n",
    "hyde = HyDEQueryTransform(llm=vertex_ai, include_original=True)\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever,\n",
    "                                              node_postprocessors=[reorder],\n",
    "                                              )\n",
    "query_engine = TransformQueryEngine(query_engine, query_transform=hyde)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Response production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 2 nodes into parent node.\n",
      "> Parent node id: 34c2ef2e-51e8-477e-afdc-c51e5eec3ba5.\n",
      "> Parent node text: การตอบสนองของพ่อแม่เมื่อเกิดอาการ โดยการตามใจ ทำให้ลูกแสดงอาการมากขึ้น วิธีการแก้ไข เด็กปกติที่กล...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"ถ้ามีอาการเจ็บหน้าอกและหอบหืดขณะออกกำลังกายควรปรึกษาแพทย์ด้านใด\"\n",
    "response=query_engine.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting response and context nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ข้อมูลที่ให้มาไม่มีข้อมูลเกี่ยวกับอาการเจ็บหน้าอกและหอบหืดขณะออกกำลังกาย ดังนั้นจึงไม่สามารถตอบคำถามได้'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: b1384542-fde3-4c50-814f-4e77cdf40f1b\n",
      "Text: โรคบางอย่างท่ีนำมาด้วยอาการท้องผูก\n",
      "เช่นโรคที่มีไทรอยด์ฮอร์โมนต�่า เด็กมักมีปัญหา พัฒนาการช้าร่วมด้วย ฯลฯ\n",
      "หากสงสัยโรคดังกล่าวควรพาลูกไปพบแพทย์ วิธีการแก้ไข 1.\n",
      "Score:  0.744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'โรคบางอย่างท่ีนำมาด้วยอาการท้องผูก เช่นโรคที่มีไทรอยด์ฮอร์โมนต�่า เด็กมักมีปัญหา พัฒนาการช้าร่วมด้วย ฯลฯ หากสงสัยโรคดังกล่าวควรพาลูกไปพบแพทย์ วิธีการแก้ไข 1.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes[0].node.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.source_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context Transformations - PII Example\n",
    "- adding context to model response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pii_processor = NERPIINodePostprocessor()\n",
    "\n",
    "def filter_pii_fn(**kwargs):\n",
    "    # run optimizer\n",
    "    query_bundle = QueryBundle(query_str=kwargs[\"query_str\"])\n",
    "\n",
    "    new_nodes = pii_processor.postprocess_nodes(\n",
    "        [NodeWithScore(node=TextNode(text=kwargs[\"context_str\"]))],\n",
    "        query_bundle=query_bundle,\n",
    "    )\n",
    "    new_node = new_nodes[0]\n",
    "    return new_node.get_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever = index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_response(query):\n",
    "    response = query_engine.query(query)\n",
    "    return response\n",
    "\n",
    "def produce_context(query):\n",
    "    retrieved_nodes = vector_retriever.retrieve(query)\n",
    "    context_str = \"\\n\\n\".join([n.get_content() for n in retrieved_nodes])\n",
    "    return context_str\n",
    "\n",
    "# model_resp_df['model_response'] = model_resp_df['question'].apply(produce_response)\n",
    "# time.sleep(5)\n",
    "# model_resp_df['context'] = model_resp_df['question'].apply(produce_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 2 nodes into parent node.\n",
      "> Parent node id: 34c2ef2e-51e8-477e-afdc-c51e5eec3ba5.\n",
      "> Parent node text: การตอบสนองของพ่อแม่เมื่อเกิดอาการ โดยการตามใจ ทำให้ลูกแสดงอาการมากขึ้น วิธีการแก้ไข เด็กปกติที่กล...\n",
      "\n",
      "response:  ข้อมูลที่ให้มาไม่มีข้อมูลเกี่ยวกับอาการเจ็บหน้าอกและหอบหืดขณะออกกำลังกาย ดังนั้นจึงไม่สามารถตอบคำถามได้\n",
      "context:  โรคบางอย่างท่ีนำมาด้วยอาการท้องผูก เช่นโรคที่มีไทรอยด์ฮอร์โมนต�่า เด็กมักมีปัญหา พัฒนาการช้าร่วมด้วย ฯลฯ หากสงสัยโรคดังกล่าวควรพาลูกไปพบแพทย์ วิธีการแก้ไข 1. ถ้าลูกอายุ 1-3 เดือน ยังกินนมแม่และนมผสม ควรงดนมผสมทั้งหมด ถ้าไม่ดีขึ้นให้น�้าส้มคั้น โดยไม่ต้องเจือจาง ถ้าอุจจาระลูกยังแข็ง ให้เปลี่ยนเป็นน�้าลูกพรุน 2. แนะนำให้ลูกกินอาหารที่มีกากใยมากขึ้น เช่น ผัก ผลไม้ ธัญพืช และดื่มน�้ามากๆ 3. ฝึกนัง่อุจจาระทกุวนัหลงัอาหารเช้า เยน็ นานคร้ังละ 5-10 นาที พ่อแม่ควรทำบนัทึกไว้ทกุครัง้ พร้อมทั้งให้คำชมเชยเมื่อลูกทำได้ หากลูกต้านการใช้กระโถน ควรเว้นไปสักระยะก่อน รอจนกว่าลูกจะ พร้อม แล้วค่อยฝึกใหม่ 4. การใช้ยาระบายหรือยาสวนควรอยู่ภายใต้การดูแลของแพทย์ ปัญหาที่พบบ่อยในเด็กอายุ 0-3 ปี\n",
      "\n",
      "การตอบสนองของพ่อแม่เมื่อเกิดอาการ โดยการตามใจ ทำให้ลูกแสดงอาการมากขึ้น วิธีการแก้ไข เด็กปกติที่กลั้นหายใจ 1-2 นาที ซึ่งอาจทำให้ตัวอ่อนหรือปากเขียวนั้น ร่างกายของเด็กจะปรับให้ เดก็กลบัมาหายใจได้เองโดยอตัโนมตั ิอาการต่างๆ ทีเ่กดิจากการร้องกลัน้หายใจนีไ้ม่เป็นอนัตรายต่อร่างกาย หรือพัฒนาการของเด็ก ซึ่งโดยปกติอาการนี้จะค่อยๆ ลดน้อยลงและหายไปเองได้หลังอายุ 2-3 ปี ดังนั้น 1. ในรายที่มีอาการครั้งแรก ควรปรึกษาแพทย์เพ่ือตรวจประเมินว่ามีความผิดปกติของระบบ หัวใจ และระบบประสาทหรือไม่ 2. ป้องกันการเกิดอาการ โดยหลีกเลี่ยงการกระตุ้นให้เด็กกลัว ตกใจ หรือโกรธ หลีกเลี่ยงการ บังคับหรือขัดใจโดยไม่จำเป็น แต่ไม่ตามใจเด็กเมื่อเกิดอาการ ควรห้ามด้วยความนุ่มนวล อาจใช้วิธีเบี่ยง เบนความสนใจของเด็กไปยังสิ่งอื่นแทน 3. เมื่อเด็กร้องกลั้น อย่าตกใจ ให้จัดการด้วยความสงบ โดยการอุ้มหรือให้เด็กนอนราบกับพื้น เพื่อป้องกันอันตรายจากการล้ม ศีรษะกระแทก เมื่อเด็กรู้ตัว ไม่ให้ในสิ่งที่เด็กเรียกร้องแต่ควรเบี่ยงเบน ความสนใจของเด็กไปยังสิ่งอื่นแทน 4. ปรับการเลี้ยงดูให้เหมาะสม ผู้ใหญ่ในบ้านควรใช้วิธีการแบบเดียวกันในการเลี้ยงดูและปรับ พฤติกรรม ปัญหาที่พบบ่อยในเด็กอายุ 0-3 ปี\n"
     ]
    }
   ],
   "source": [
    "query = \"ถ้ามีอาการเจ็บหน้าอกและหอบหืดขณะออกกำลังกายควรปรึกษาแพทย์ด้านใด\"\n",
    "response = produce_response(query)\n",
    "context =  produce_context(query)\n",
    "\n",
    "print(\"response:\" , response)\n",
    "print(\"context: \" , context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
